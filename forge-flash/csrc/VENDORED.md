# Vendored Sources

- FlashAttention v2: https://github.com/Dao-AILab/flash-attention (main branch)
- CUTLASS: https://github.com/NVIDIA/cutlass (main branch)

To update: re-clone and copy as described in the implementation plan.
